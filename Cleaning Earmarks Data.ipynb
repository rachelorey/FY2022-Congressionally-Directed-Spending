{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "874e29c8",
   "metadata": {},
   "source": [
    "# Cleaning Full Congressionally Directed Spending Dataset\n",
    "\n",
    "source of current legislators data: https://github.com/unitedstates/congress-legislators/blob/main/README.md \n",
    "\n",
    "Steps taken in Excel prior to cleaning: \n",
    "1. Each of the current legislators (from above source) were given an 'index' so more easily match and parse through rows.\n",
    "2. Got list of all legislators with duplicate last names. Further sorted that list by duplicate within House/Senate and within the same state.\n",
    "3. Got list of unique requestors grouped by \"House Requestors\", \"Senate Requestors\", and \"General\" (Defense did not indicate, though those were only allowed in House). Because the appropriations data often only included last name, the unique last names were used as a key and linked with the index from the current legislators dataset. If the last names were duplicates, the dataset was filtered by state first. If there was no state provided or if the name is a duplicate from within the same state, \"statedup\" or \"no match\" was given instead as a warning to collect by hand later. \n",
    "4. Single \"Requestors\" columns were split using Excel's 'Text to Column' feature, with commas and semicolons used as delimiters. Each requestor was then linked with the corresponding index from the current-legislators dataset. That resulted in a structure with \"Requestor One\"/\"Requestor One Index\" and so on \n",
    "5. Occasionally, columns other than state included state abbreviations at the end of the string (for example at the end of Project or Location). Went and used an Excel formula to extract those into the State column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27deccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "220e8275",
   "metadata": {},
   "outputs": [],
   "source": [
    "earmarks = pd.read_csv(\"C:\\\\Users\\\\rorey\\\\OneDrive - Bipartisan Policy Center\\\\Congress\\\\Earmarks Data\\\\fulldataset.csv\",encoding='utf-8-sig')\n",
    "states = pd.read_csv(\"C:\\\\Users\\\\rorey\\\\OneDrive - Bipartisan Policy Center\\\\Congress\\\\Earmarks Data\\\\stateabbs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1dc430",
   "metadata": {},
   "source": [
    "### Cleaning Requestor Columns\n",
    "Removing misc spaces and text from requestors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "13cd8b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##already done -- encoding current legislators (download not properly encoded - has errors with accents in names, etc)\n",
    "# legog = pd.read_csv(\"C:\\\\Users\\\\rorey\\\\OneDrive - Bipartisan Policy Center\\\\Congress\\\\Earmarks Data\\\\legislators-current_OG.csv\",encoding='utf-8-sig')\n",
    "# legog.to_csv(\"C:\\\\Users\\\\rorey\\\\OneDrive - Bipartisan Policy Center\\\\Congress\\\\Earmarks Data\\\\legislators-current_encoded.csv\",encoding='utf-8-sig',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6481039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Requestor One (House)','Requestor Two (House)','Requestor Three (House)','Requestor Four (House)','Requestor One (Senate)','Requestor Two (Senate)','Requestor Three (Senate)','Requestor Four (Senate)','Requestor Five (Senate)','Requestor One (General)','Requestor Two (General)']\n",
    "\n",
    "def clean_strip(string):\n",
    "    if (not pd.isnull(string)) and (string != \"NaN\"):\n",
    "        return(str(string).strip())\n",
    "    else:\n",
    "        return('')\n",
    "\n",
    "for col in cols:\n",
    "    earmarks[col] = earmarks[col].map(lambda x: clean_strip(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583ffeb5",
   "metadata": {},
   "source": [
    "### Cleaning \"State\" column\n",
    "- Replace full state names with abbreviations\n",
    "- use regular expressions to extact states embedded in Project strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ab405c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace full state names with abbreviations\n",
    "stated = states.set_index(\"State\",drop=True)\n",
    "stated = stated.to_dict('dict')[\"Code\"]\n",
    "\n",
    "for index,row in earmarks[earmarks[\"State\"].isin(states[\"State\"])].iterrows():\n",
    "    earmarks.loc[index,\"State\"] = stated.get(earmarks.loc[index,\"State\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea29d44e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##FIRST LEVEL: state in bewteen two commas\n",
    "\n",
    "extracted = earmarks[earmarks['State'].isna()][\"Project\"].str.extract(r'(, [A-Z]{2},)')\n",
    "# extracted[0].unique()\n",
    "extracted[0] = extracted[0].str.replace(\" \",\"\")\n",
    "extracted[0] = extracted[0].str.replace(\",\",\"\")\n",
    "\n",
    "\n",
    "for index,row in earmarks[earmarks['State'].isna()].iterrows():\n",
    "    if extracted[0].loc[index] in states[\"Code\"].values:\n",
    "        earmarks.loc[index,\"State\"] = extracted[0].loc[index]\n",
    "        \n",
    "        \n",
    "##SECOND LEVEL (not including second comma)\n",
    "        \n",
    "extracted = earmarks[earmarks['State'].isna()][\"Project\"].str.extract(r'(, [A-Z]{2} )')\n",
    "extracted[0] = extracted[0].str.replace(\" \",\"\")\n",
    "extracted[0] = extracted[0].str.replace(\",\",\"\")\n",
    "extracted[0].unique()\n",
    "\n",
    "\n",
    "for index,row in earmarks[earmarks['State'].isna()].iterrows():\n",
    "    if extracted[0].loc[index] in states[\"Code\"].values:\n",
    "        earmarks.loc[index,\"State\"] = extracted[0].loc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff85b44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "earmarks.fillna('', inplace=True)\n",
    "earmarks.to_csv(\"C:\\\\Users\\\\rorey\\\\OneDrive - Bipartisan Policy Center\\\\Congress\\\\Earmarks Data\\\\fulldataset_revised.csv\",encoding='utf-8-sig',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6745e8ac",
   "metadata": {},
   "source": [
    "# Further Cleaning and Collapsing CDS Dataset\n",
    "After above steps were completed, dataset was analyzed in excel and cleaned. Sometimes, first names were split from last names as if second requestors. Those were removed where apparent.\n",
    "\n",
    "That cleaned dataset was then brought back here for further cleaning. The indexes were linked with the legislators-current dataset to extract full name, party, and chamber. Empty columns were dropped and data was moved left (previously, when requestors were seperated by House and Senate and General there were empty cells when requestors came from just one; in this analysis, the column seperation was removed and it was just \"Requestors\", as the legislators themselves now had chamber attached)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c86bdf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "earmarks = pd.read_csv(\"C:\\\\Users\\\\rorey\\\\OneDrive - Bipartisan Policy Center\\\\Congress\\\\Earmarks Data\\\\fulldataset_filled.csv\",encoding='cp1252')\n",
    "legs = pd.read_csv(\"C:\\\\Users\\\\rorey\\\\OneDrive - Bipartisan Policy Center\\\\Congress\\\\Earmarks Data\\\\legislators-current_encoded.csv\",encoding='utf-8-sig')\n",
    "\n",
    "#isolate requestor columns for squeezing\n",
    "cols = ['Requestor One (House)', 'index', 'Requestor Two (House)', 'index2',\n",
    "       'Requestor Three (House)', 'index3', 'Requestor Four (House)', 'index4',\n",
    "       'Requestor One (Senate)', 'index5', 'Requestor Two (Senate)', 'index6',\n",
    "       'Requestor Three (Senate)', 'index7', 'Requestor Four (Senate)',\n",
    "       'index8', 'Requestor Five (Senate)', 'index9',\n",
    "       'Requestor One (General)', 'index10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec5ead1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\"collapse\" dataset so that empty cells removed and requestors info moved left (differentiaion in columns between H/S removed allowing for this). Store temporarily in 'test' dataset\n",
    "def squeeze_nan(x):\n",
    "    import numpy as np\n",
    "    original_columns = x.index.tolist()\n",
    "\n",
    "    squeezed = x.dropna()\n",
    "    squeezed.index = [original_columns[n] for n in range(squeezed.count())]\n",
    "\n",
    "    return squeezed.reindex(original_columns, fill_value=np.nan)\n",
    "\n",
    "test = earmarks[cols].apply(squeeze_nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cb0b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.dropna(axis=1,how='all') #remove columns with only NA values\n",
    "test.columns = ['Requestor One','Requestor One Index', #rename remaining columns\n",
    " 'Requestor Two','Requestor Two Index',\n",
    " 'Requestor Three','Requestor Three Index',\n",
    " 'Requestor Four','Requestor Four Index',\n",
    " 'Requestor Five','Requestor Five Index',\n",
    " 'Requestor Six','Requestor Six Index',\n",
    " 'Requestor Seven','Requestor Seven Index',\n",
    " 'Requestor Eight','Requestor Eight Index',\n",
    " 'Requestor Nine','Requestor Nine Index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56508ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "earmarks.drop(cols,axis=1,inplace=True) ## drop cols from earmarks that were extracted into test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3296d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "earmarks = earmarks.join(test) #join collapsed requestors info (\"test\") with earmarks df\n",
    "earmarks = earmarks.dropna(axis=1,how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5477682f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## get only relevant data from legislators-current dataset. convert to dict for easy linking\n",
    "legs = legs[['index','full_name','bioguide_id','party','type']]\n",
    "legs.set_index('index',inplace=True,drop=True)\n",
    "legs_dict = legs.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ed985cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each column of requestors, use index to get name, party, and chamber from lesiglators-current dataset\n",
    "vals = ['Requestor One','Requestor Two','Requestor Three','Requestor Four','Requestor Five','Requestor Six','Requestor Seven','Requestor Eight','Requestor Nine']\n",
    "for val in vals:\n",
    "    earmarks[val + ' Full Name'] = earmarks[val + ' Index'].map(lambda x: legs_dict['full_name'].get(int(x)) if (x != \"statedup\") and (x != \"no match\") and (not pd.isnull(x)) else x)\n",
    "    earmarks[val + ' Party'] = earmarks[val + ' Index'].map(lambda x: legs_dict['party'].get(int(x)) if (x != \"statedup\") and (x != \"no match\") and (not pd.isnull(x)) else x)\n",
    "    earmarks[val + ' Chamber'] = earmarks[val + ' Index'].map(lambda x: legs_dict['type'].get(int(x)) if (x != \"statedup\") and (x != \"no match\") and (not pd.isnull(x)) else x)\n",
    "    earmarks[val + ' bioguide_id'] = earmarks[val + ' Index'].map(lambda x: legs_dict['bioguide_id'].get(int(x)) if (x != \"statedup\") and (x != \"no match\") and (not pd.isnull(x)) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c148b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ordering columns\n",
    "earmarks = earmarks[['Category', 'Agency', 'Account', 'Project', 'Recipient', 'Location',\n",
    "    'State', 'Budget Request', 'Additional Amount', 'Amount', 'Origination',\n",
    "    'Requestor One', 'Requestor One Index','Requestor One Full Name','Requestor One bioguide_id','Requestor One Chamber','Requestor One Party',\n",
    "    'Requestor Two','Requestor Two Index','Requestor Two Full Name','Requestor Two bioguide_id','Requestor Two Chamber','Requestor Two Party', \n",
    "    'Requestor Three', 'Requestor Three Index','Requestor Three Full Name','Requestor Three bioguide_id','Requestor Three Chamber','Requestor Three Party',\n",
    "    'Requestor Four', 'Requestor Four Index','Requestor Four Full Name','Requestor Four bioguide_id','Requestor Four Chamber','Requestor Four Party',\n",
    "    'Requestor Five','Requestor Five Index','Requestor Five Full Name','Requestor Five bioguide_id','Requestor Five Chamber','Requestor Five Party',\n",
    "    'Requestor Six', 'Requestor Six Index','Requestor Six Full Name','Requestor Six bioguide_id','Requestor Six Chamber','Requestor Six Party', \n",
    "    'Requestor Seven', 'Requestor Seven Index','Requestor Seven Full Name','Requestor Seven bioguide_id','Requestor Seven Chamber','Requestor Seven Party',\n",
    "    'Requestor Eight','Requestor Eight Index','Requestor Eight Full Name','Requestor Eight bioguide_id','Requestor Eight Chamber','Requestor Eight Party',\n",
    "    'Requestor Nine', 'Requestor Nine Index','Requestor Nine Full Name','Requestor Nine bioguide_id','Requestor Nine Chamber','Requestor Nine Party']]\n",
    "\n",
    "##stripping extra spaces\n",
    "df_obj = earmarks.select_dtypes(['object'])\n",
    "earmarks[df_obj.columns] = df_obj.apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2f1b05e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#drop misc columns from sharing dataset\n",
    "earmarks_forsharing = earmarks.drop(['Requestor One','Requestor One Index',\n",
    " 'Requestor Two','Requestor Two Index',\n",
    " 'Requestor Three','Requestor Three Index',\n",
    " 'Requestor Four','Requestor Four Index',\n",
    " 'Requestor Five','Requestor Five Index',\n",
    " 'Requestor Six','Requestor Six Index',\n",
    " 'Requestor Seven','Requestor Seven Index',\n",
    " 'Requestor Eight','Requestor Eight Index',\n",
    " 'Requestor Nine','Requestor Nine Index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c72f41ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = earmarks_forsharing.columns\n",
    "earmarks_forsharing.columns = [col.replace(\" \",\"_\").lower() for col in cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6396a935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "earmarks.to_csv(\"C:\\\\Users\\\\rorey\\\\OneDrive - Bipartisan Policy Center\\\\Congress\\\\Earmarks Data\\\\dataset_adjustedwithmembers.csv\",encoding='utf-8-sig',index=False)\n",
    "earmarks_forsharing.to_csv(\"C:\\\\Users\\\\rorey\\\\OneDrive - Bipartisan Policy Center\\\\Congress\\\\Earmarks Data\\\\earmarks_forsharing.csv\",encoding='utf-8-sig',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
